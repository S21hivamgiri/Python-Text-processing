{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Challenge - Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Assignment Comprise of:\n",
    "\n",
    "1.   Write a program to split the below paragraph into different sentences.\n",
    "“For the third time this monsoon, pounding rains paralysed Mumbai on Wednesday with total disruption in road and rail traffic, though flights were not hit severely. Mumbai turned into an extension of the sea as unprecedented rains deluged the country's financial capital, delaying flights, jamming traffic, flooding homes and having rescue teams out on the roads since morning. In several places, the local trains grinded to a halt, and long distance trains were cancelled. In the evening office hours, the waterlogging pushed people to look for the nearest shelter, abandoning thoughts of reaching home. The met office declared a red alert for the next 24 hours, indicating that the situation might worsen. Schools and junior colleges in Mumbai, Thane and Konkan will remain shut on Thursday as a precautionary measure.”\n",
    "\n",
    "\n",
    "2.   Stop words are commonly used words (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.NLTK has a list of English stop words.Write down a program to make a list of words from above paragraph other than stop words.\n",
    "\n",
    "3.   Write a program to make a list of all nouns in above paragraph\n",
    "\n",
    "4.   Write a program to transform all verbs in above paragraph to their respective base form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split the paragraph into different sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Loading the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Split the paragraph into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"For the third time this monsoon, pounding rains paralysed Mumbai on Wednesday with total disruption in road and rail traffic, though flights were not hit severely. Mumbai turned into an extension of the sea as unprecedented rains deluged the country's financial capital, delaying flights, jamming traffic, flooding homes and having rescue teams out on the roads since morning. In several places, the local trains grinded to a halt, and long distance trains were cancelled. In the evening office hours, the waterlogging pushed people to look for the nearest shelter, abandoning thoughts of reaching home. The met office declared a red alert for the next 24 hours, indicating that the situation might worsen. Schools and junior colleges in Mumbai, Thane and Konkan will remain shut on Thursday as a precautionary measure.\"\n",
    "sentences = nltk.sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Print the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the third time this monsoon, pounding rains paralysed Mumbai on Wednesday with total disruption in road and rail traffic, though flights were not hit severely.\n",
      "Mumbai turned into an extension of the sea as unprecedented rains deluged the country's financial capital, delaying flights, jamming traffic, flooding homes and having rescue teams out on the roads since morning.\n",
      "In several places, the local trains grinded to a halt, and long distance trains were cancelled.\n",
      "In the evening office hours, the waterlogging pushed people to look for the nearest shelter, abandoning thoughts of reaching home.\n",
      "The met office declared a red alert for the next 24 hours, indicating that the situation might worsen.\n",
      "Schools and junior colleges in Mumbai, Thane and Konkan will remain shut on Thursday as a precautionary measure.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Print list of words other than stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Loading the new library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Getting the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Listing of words from other than stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words=[]\n",
    "for i in words:\n",
    "    if i not in stop_words:\n",
    "        new_words.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5:  Print without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'third', 'time', 'monsoon', ',', 'pounding', 'rains', 'paralysed', 'Mumbai', 'Wednesday', 'total', 'disruption', 'road', 'rail', 'traffic', ',', 'though', 'flights', 'hit', 'severely', '.', 'Mumbai', 'turned', 'extension', 'sea', 'unprecedented', 'rains', 'deluged', 'country', \"'s\", 'financial', 'capital', ',', 'delaying', 'flights', ',', 'jamming', 'traffic', ',', 'flooding', 'homes', 'rescue', 'teams', 'roads', 'since', 'morning', '.', 'In', 'several', 'places', ',', 'local', 'trains', 'grinded', 'halt', ',', 'long', 'distance', 'trains', 'cancelled', '.', 'In', 'evening', 'office', 'hours', ',', 'waterlogging', 'pushed', 'people', 'look', 'nearest', 'shelter', ',', 'abandoning', 'thoughts', 'reaching', 'home', '.', 'The', 'met', 'office', 'declared', 'red', 'alert', 'next', '24', 'hours', ',', 'indicating', 'situation', 'might', 'worsen', '.', 'Schools', 'junior', 'colleges', 'Mumbai', ',', 'Thane', 'Konkan', 'remain', 'shut', 'Thursday', 'precautionary', 'measure', '.']\n"
     ]
    }
   ],
   "source": [
    "print(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print list of nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Loading the new library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\SHIVAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Tagging Part-of-speech in the tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "postags = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Step 3: Getting a nested nltk.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks= ne_chunk(postags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Step 4: Segregating the nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns=[]\n",
    "for i in chunks:\n",
    "    if 'NN' in i or 'NNS' in i or 'NNP' in i:\n",
    "        nouns.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Step 5: Printing the nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'monsoon', 'rains', 'Wednesday', 'disruption', 'road', 'rail', 'traffic', 'flights', 'extension', 'sea', 'rains', 'country', 'capital', 'flights', 'traffic', 'homes', 'rescue', 'teams', 'roads', 'morning', 'places', 'trains', 'halt', 'distance', 'trains', 'evening', 'office', 'hours', 'waterlogging', 'people', 'shelter', 'thoughts', 'home', 'office', 'alert', 'hours', 'situation', 'colleges', 'shut', 'Thursday', 'measure']\n"
     ]
    }
   ],
   "source": [
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing list of verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Step 1: Segregating the verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs=[]\n",
    "for i in chunks:\n",
    "    if 'VB' in i or 'VBD' in i or 'VBN' in i or 'VBG' in i or 'VBP' in i or 'VBZ' in i:\n",
    "        verbs.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Step 2: Printing the verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pounding', 'paralysed', 'were', 'hit', 'turned', 'deluged', 'delaying', 'jamming', 'flooding', 'having', 'grinded', 'were', 'cancelled', 'pushed', 'look', 'abandoning', 'reaching', 'declared', 'indicating', 'worsen', 'remain']\n"
     ]
    }
   ],
   "source": [
    "print(verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence the Asssignment Completed successfuly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
